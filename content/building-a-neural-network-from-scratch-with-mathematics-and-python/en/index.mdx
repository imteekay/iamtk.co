<SmoothRender>

I've been studying machine learning and AI for quite some time now but neural networks caught my attention because of their nature of modeling, understanding, and learning abstract, complex, and unstructured data. It's been 2 or 3 months that I've been reading books, doing courses, and coding neural nets but I was eager to officially write down all my notes and learnings.

This post aims to be a comprehensive article about neural networks, how mathematics works, and provide an implementation from scratch in Python and Numpy, without any other framework, like Tensorflow or Pytorch.

Here are the following topics I'm going to cover in this post:

### Table of Contents

- Introduction of Neural Networks
- Mathematics of Neural Networks
- Digit Recognizer Problem & Python Implementation

## Introduction of Neural Networks

A neural network is a combination of the input, layers, neurons, and the output.

A simple neural network will receive data as input, process the data in the hidden layers through linear combinations and activation functions, and result in an output. The output can be a label — for binary or multiclass classification problems — or a continuous value if we are working with a regression problem.

For a simple neural network, let's say a 2-layer neural network, it has an input layer, a hidden layer where we do our first linear combination together with the application of an activation function, and then we have our second layer, also called, in this case, the output layer, where we also have a linear combination and then apply a different activation function to classify or predict an estimate, depending on the problem.

For the input layer, we use the symbol `X` and this is a matrix of all features and training examples. The features are usually the columns and the rows are all training examples. It's commonly used `m` as the number of rows (training examples) and `n` as the number of columns (features).

And then we have the hidden layer. The neural network makes a bunch of connections between the input and the hidden layers.

==== Add illustration of a connection between the input and hidden layers ====

Each neuron, also called a hidden unit, will do two main things:

- Compute a linear combination (input, weight, and bias)
- Compute the activation function for this linear combination

The linear combination is basically the input data times a weight `w` plus a bias term `b`. Both `w` and `b` are parameters that the neural network will use in the learning process.

<BlockMath>{`\\begin{equation}z = w x + b\\end{equation}`}</BlockMath>

In linear algebra, linear combinations are usually symbolized with a `z`.

After the linear combination, we need to apply an activation function. It's a non-linear function to add complexity to the model. Different types of functions can be applied here: sigmoid, tanh, ReLU, etc.

Activation functions allow the network to learn and represent complex patterns by introducing non-linearities, enabling it to approximate complex functions. It also helps the neural network to generalize and learn abstract features. It also allows gradients to be meaningful, enabling efficient learning.

==== Add an example of sigmoid, tanh, and relu graphs and equations ====

The output of this first hidden layer is represented by the symbol `A`. With many layers in the neural network, we need to name them with the layer number, like `A1`, `A2`, `A3`, etc.

The output layer has a similar structure to the hidden layer. It computes the linear combination and the activation function. The difference is that the input for this layer is `A1`, the output of the first layer and we use a different activation function to compute the prediction. For example, It can be a linear function for a regression problem, a sigmoid function for a binary classification, or softmax for a multiclass classification problem.

With the prediction, we can now measure how well our neural network model’s predictions align with the actual target values. In other words, we compute a loss function.

==== Add an illustration of the whole neural network ====

This whole process from input to the hidden layer to the output layer and finally resulting in a prediction is called **_forward propagation_**.

If we only compute the forward propagation, we only have one estimate and the neural network is not really learning anything. It just calculated one prediction. So we need a way to make the neural network learns. This learning process is a combination of backpropagation and an optimization algorithm (e.g. gradient descent).

The backpropagation process starts from the output and goes all the way to the starting point of the neural network. The idea is to compute derivatives of the loss function with respect to parameters like weights and biases for the different layers. Because the loss function measures how the model is performing, we want to minimize it as much as possible so it can perform better and better. With these calculations, we know the rate of change between the loss function and the parameter (weight and bias) so we can update the weights and biases with the goal of minimizing the loss function, enabling the neural network to learn and perform better.

We can repeat this back-and-forward process many times, updating the parameters (weights and biases) to minimize the loss function. In other words, we make the neural network learn better in each iteration.

## Mathematics of Neural Networks

Let's now build up the maths for the neural network. We'll start with the forward propagation and do backpropagation right after.

====== illustration of the neural network ======

We have a matrix as the input layer and we'll use it as the input for the first hidden layer. The symbol we use here is `X`.

To compute the hidden layer, we first need to compute the linear combination:

<BlockMath>{`\\begin{equation}Z^{[1]} = W^{[1]} X + B^{[1]}\\end{equation}`}</BlockMath>

We call a linear combination as `Z`, or in this case `Z1` because it's the linear combination of the first layer.

Then we need to apply the activation function, symbolized by `g1`, resulting in the output of the first layer: `A1`.

<BlockMath>{`\\begin{equation}A^{[1]} = g(Z^{[1]})\\end{equation}`}</BlockMath>

In the following section, we'll talk about the classification problem we'll apply all this theory and the activation function we'll use is one called Rectified Linear Unit (ReLU) which is a very simple function and easy to implement and derive.

<BlockMath>{`\\begin{equation}f(Z) = max(Z, 0)\\end{equation}`}</BlockMath>

In words, the ReLU function outputs:

- z if z > 0
- 0 if z ≤ 0.

All of this is for the first layer. The second layer is pretty much the same idea but we annotate the symbols with `2` to specify we are talking about the second one.

<BlockMath>{`\\begin{equation}Z^{[2]} = W^{[2]} A^{[1]} + B^{[2]}\\end{equation}`}</BlockMath>

<BlockMath>{`\\begin{equation}A^{[2]} = g(Z^{[2]})\\end{equation}`}</BlockMath>

For the second activation function, we'll be using a different one than ReLU because we want to compute the probability of multi-label classification. The function is called softmax.

<BlockMath>{`\\begin{equation}softmax(x_i) = \\frac{e^{x_i}}{\sum_{j=1}^{k} e^{x_j}}\\end{equation}`}</BlockMath>

The output of this function is the probability of all input values. The predicted label will be the class with a higher probability score. All the possible labels have a probability and if sum all of them, we get 1 (or 100%).

After finishing the forward propagation, we need to compute the backpropagation. Mathematically, this step is the real challenge, especially if you have a hard time with maths and calculus. The entire backpropagation is about derivatives.

But why derivatives? Because we want to compute something called gradients, and then implement an algorithm called gradient descent as the optimizer of our neural network.

Until now, what we did was to compute an output, a prediction. In this case, the probability of different classes or labels. But if we do it just one time, the neural network is not learning.

The learning process is about “how much the loss function minimizes if we change the model parameters?” and keep changing them until it's “enough”. In other words, we want to understand how much the loss function will change if we change the `w` and `b` parameters. We update them and repeat the process so for each iteration, the neural network is learning more and more patterns and performing better over time.

This concept of “rate of change” of the loss function with respect to parameter `w` or parameter `b` is basically a derivative.

==== illustration of the neural network and the derivatives of each part =====

We compute the gradients from the end of the neural network all the way to the beginning of it. Here are all the steps we need to do then:

<InlineMath>{`\\frac{dL}{dz^{[2]}} =
dz^{[2]} =`}</InlineMath> derivative of the loss function with respect to <InlineMath>{`z^{[2]}`}</InlineMath>

<InlineMath>{`\\frac{dL}{dw^{[2]}} =
dw^{[2]} =`}</InlineMath> derivative of the loss function with respect to <InlineMath>{`w^{[2]}`}</InlineMath>

<InlineMath>{`\\frac{dL}{db^{[2]}} =
db^{[2]} =`}</InlineMath> derivative of the loss function with respect to <InlineMath>{`b^{[2]}`}</InlineMath>

<InlineMath>{`\\frac{dL}{dz^{[1]}} =
dz^{[1]} =`}</InlineMath> derivative of the loss function with respect to <InlineMath>{`z^{[1]}`}</InlineMath>

<InlineMath>{`\\frac{dL}{dw^{[1]}} =
dw^{[1]} =`}</InlineMath> derivative of the loss function with respect to <InlineMath>{`w^{[1]}`}</InlineMath>

<InlineMath>{`\\frac{dL}{db^{[1]}} =
db^{[1]} =`}</InlineMath> derivative of the loss function with respect to <InlineMath>{`b^{[1]}`}</InlineMath>

Let's compute that.

To compute <InlineMath>{`{dz^{[2]}}`}</InlineMath>, we need to do the derivative of the loss function and <InlineMath>{`{dz^{[2]}}`}</InlineMath>. This is basically the chain rule: To compute <InlineMath>{`\\frac{dL}{dz^{[2]}} = \\frac{dL}{da} \\cdot \\frac{da}{dz^{[2]}}`}</InlineMath>, which is calculated as <InlineMath>{`{a}^{[2]} - y`}</InlineMath>, where <InlineMath>{`{a}^{[2]}`}</InlineMath> is the predicted value and <InlineMath>{`y`}</InlineMath> is the real label.

For the weight in the second layer, we compute this derivative: <InlineMath>{`\\frac{dL}{dw^{[2]}} = {dw^{[2]}} = \\frac{dL}{dz^{[2]}} \\cdot \\frac{dz^{[2]}}{dw^{[2]}} = {({a}^{[2]} - y)} \\cdot {a^{[1]}}^T`}</InlineMath>.

The computation for the bias is similar to the weight but we compute the derivative of the loss function with respect to the weight in the second layer: <InlineMath>{`\\frac{dL}{db^{[2]}} = {db^{[2]}} = \\frac{dL}{dz^{[2]}} \\cdot \\frac{dz^{[2]}}{db^{[2]}} = {dz^{[2]}}`}</InlineMath>.

<InlineMath>{`\\frac{dL}{dz^{[1]}} = {dz^{[1]}}`}</InlineMath>: the derivative
of the loss function with respect to <InlineMath>{`z^{[1]}`}</InlineMath> is a bigger
chain rule: <InlineMath>{`\\frac{dL}{dz^{[2]}} \\cdot \\frac{dz^{[2]}}{da^{[1]}} \\cdot \\frac{da^{[1]}}{dz^{[1]}}`}</InlineMath>
, producing <InlineMath>{`{w^{[2]}}^T \\cdot {dz^{[2]}} \\cdot g\\'(z^{[1]})`}</InlineMath>

<InlineMath>{`g\\'(z^{[1]})`}</InlineMath> is the derivative of the loss
function with respect to the activation function <InlineMath>{`g`}</InlineMath>.
In the example of this post, we need to do the derivative of the ReLU activation
function.

Because a ReLU function is <InlineMath>{`z`}</InlineMath> if <InlineMath>{`z > 0`}</InlineMath> and 0 if <InlineMath>{`z \\le 0`}</InlineMath>, the derivative of it is 1 if <InlineMath>{`z > 0`}</InlineMath> and 0 if <InlineMath>{`z \\le 0`}</InlineMath>. In the practice example, we'll see how this is very simple to implement in Python and Numpy.

The derivative of <InlineMath>{`\\frac{dL}{dw^{[1]}} = {dw^{[1]}}`}</InlineMath> is <InlineMath>{`\\frac{dL}{dz^{[2]}} \\cdot \\frac{dz^{[2]}}{da^{[1]}} \\cdot \\frac{da^{[1]}}{dz^{[1]}} \\cdot \\frac{dz^{[1]}}{dw^{[1]}}`}</InlineMath>, producing <InlineMath>{`dz^{[1]} \\cdot x^T`}</InlineMath>

The derivative of <InlineMath>{`\\frac{dL}{db^{[1]}} = {db^{[1]}}`}</InlineMath> is <InlineMath>{`\\frac{dL}{dz^{[2]}} \\cdot \\frac{dz^{[2]}}{da^{[1]}} \\cdot \\frac{da^{[1]}}{dz^{[1]}} \\cdot \\frac{dz^{[1]}}{db^{[1]}}`}</InlineMath>, producing <InlineMath>{`dz^{[1]}`}</InlineMath>

That's so interestingly intuitive because if we see the chain rule, we can see the backpropagation in this computation from <InlineMath>{`z^{[2]}`}</InlineMath> to the first parameters <InlineMath>{`w^{[1]}`}</InlineMath> and <InlineMath>{`b^{[1]}`}</InlineMath>.

So here are all the derivatives together:

<BlockMath>{`\\begin{equation}\\frac{dL}{dz^{[2]}} = dz^{[2]} = {a}^{[2]} - y\\end{equation}`}</BlockMath>

<BlockMath>{`\\begin{equation}\\frac{dL}{dw^{[2]}} = dw^{[2]} = {({a}^{[2]} - y)} \\cdot {a^{[1]}}^T\\end{equation}`}</BlockMath>

<BlockMath>{`\\begin{equation}\\frac{dL}{db^{[2]}} = db^{[2]} = dz^{[2]}\\end{equation}`}</BlockMath>

<BlockMath>{`\\begin{equation}\\frac{dL}{dz^{[1]}} = dz^{[1]} = {w^{[2]}}^T \\cdot {dz^{[2]}} \\cdot g\\'(z^{[1]})\\end{equation}`}</BlockMath>

<BlockMath>{`\\begin{equation}\\frac{dL}{dw^{[1]}} = dw^{[1]} = dz^{[1]} \\cdot x^T\\end{equation}`}</BlockMath>

<BlockMath>{`\\begin{equation}\\frac{dL}{db^{[1]}} = db^{[1]} = dz^{[1]}\\end{equation}`}</BlockMath>

## Resources

- [Mathematics for Machine Learning](/mathematics-for-machine-learning)
- [Machine Learning Research](https://github.com/imteekay/machine-learning-research)
- [Derivation of DL/dz](https://community.deeplearning.ai/t/derivation-of-dl-dz/165)
- [Building a neural network from scratch](https://www.youtube.com/watch?v=w8yWXqWQYmU)

</SmoothRender>
