<SmoothRender>

As you may know, I've been studying compilers. A lot. For the past month, I've been learning more about the TypeScript compiler, reading its source code, and implementing some of the exercises from the [mini-typescript](https://github.com/imteekay/mini-typescript).

In this post, I want to cover some of my learnings while reading the TypeScript compiler miniature's source code and implementing the exercises.

I divided this series into three parts and the following posts to cover everything about the TypeScript compiler. The first two are already published and you can take a look at them here:

- [A High Level Architecture of the TypeScript compiler](https://www.iamtk.co/a-high-level-architecture-of-the-typescript-compiler)
- [JavaScript scope, Closures, and the TypeScript compiler](https://iamtk.co/javascript-scope-closures-and-the-typescript-compiler)

And now, in this post, I will cover different features of the [mini-typescript](https://github.com/imteekay/mini-typescript) and how they are implemented. For the exercises I implemented in the project, I will write new articles in the following posts of the series.

By the way, I think it's a good idea to read the first two posts before reading this if you don't know how compilers work and how the TypeScript compiler works. The first one will give a good overview of the steps of the compiler and how each piece fits together. The second one will talk about closures and how they are used to make the compiler more modular and easier to change.

With the two pieces, I think you'll be ready to read how some of the features of the TypeScript miniature are implemented.

Let's go!

---

Before going into each feature, I just want to illustrate how the compiler structures each step. Basically, how it represents tokens in the lexer step, AST nodes in the parser, variable and type declarations in the binder, and types in the type checker.

## Representing tokens

The idea of a lexer is to go through character by character and produce a new token. It receives the source code as a string and starts from position `0`. In this simplest version, it has states like `pos` as the position of the current character it's analyzing, `token` as the token type of the produced token, and `text` that could be the name of an identifier (e.g. `age` from `var age = 1;`), a number value (e.g. `1`), a keyword (e.g. `var`), or a string value (e.g. `"string"`).

As an example, if we have this source code

```jsx
var age = 1;
```

The lexer will produce this list of tokens

- `var`:
  - `text`: “var”
  - `token`: “Var”
- `age`:
  - `text`: “age”
  - `token`: “Identifier”
- `=`:
  - `text`: undefined
  - `token`: “Equals”
- `1`:
  - `text`: “1”
  - `token`: “NumericLiteral”

In a visible way, it should look like this

[Add illustration: from source code to tokens using this example above]

## Representing AST nodes

AST nodes are basically `Statement`s. They can be `ExpressionStatement`, `Var`, `TypeAlias`, or `EmptyStatement`.

The type looks like a union of all these types

```tsx
type Statement = ExpressionStatement | Var | TypeAlias | EmptyStatement;
```

To have an idea of how AST nodes can be structured, let's take `ExpressionsStatement` as an example and see its data types and the transformation from source code to AST node.

The `ExpressionStatement` can be different expressions: `Identifier`, `NumericLiteral`, `Assignment`, or `StringLiteral`.

```tsx
type Expression = Identifier | NumericLiteral | Assignment | StringLiteral;
```

Each node can have different “attributes”. For example,

- `NumericLiteral` and `StringLiteral` can have a `value` attribute. For `NumericLiteral`, it's a number and for `StringLiteral`, it's a string.
- The `Identifier` has a `text` attribute, that's its name.
- The `Assignment` has the `name` and the `value`.

Let's see how we can represent each of these nodes — their data types

```tsx
interface Identifier {
  kind: Node.Identifier;
  text: string;
  pos: number;
}

interface Assignment {
  kind: Node.Assignment;
  name: Expression;
  value: Expression;
  pos: number;
}

interface NumericLiteral {
  kind: Node.NumericLiteral;
  value: number;
  pos: number;
}

interface StringLiteral {
  kind: Node.StringLiteral;
  value: string;
  pos: number;
}
```

This is already a good node representation for each.

Let's now see examples of each node:

An identifier with name `name`:

```tsx
// source code:
// name;

const identifier = {
  kind: 'Identifier',
  text: 'name',
  pos: 0,
};
```

An assignment with name `age` and value `1`:

```tsx
// source code:
// age = 1;

const assignment = {
  kind: 'Assignment',
  name: {
    // an identifier is an expression
    kind: 'Identifier',
    text: 'age',
    pos: 0,
  },
  value: {
    // a numeric literal is an expression
    kind: 'NumericLiteral',
    value: 1,
    pos: 1,
  },
  pos: 0,
};
```

A numeric literal:

```tsx
// source code:
// 1;

const numericLiteral = {
  kind: 'NumericLiteral',
  value: 1,
  pos: 0,
};
```

A string literal:

```tsx
// source code:
// 'hello';

const stringLiteral = {
  kind: 'StringLiteral',
  value: 'hello',
  pos: 0,
};
```

This already gives us a nice overview of how we can represent the source code in AST nodes. In the following sections, we will dive deeper into each feature and see how this is used in the following steps like the binder and the type checker.

## Binder: storing the type and variable declarations

Here in the binder, one of its responsibilities is storing declarations of types and variables. The compiler stores in a data structure and the statements or AST nodes can be “fetched” later on.

The data structure the compiler uses to store these declarations is a `Map`, a key-value data structure, where the key is the name of the identifier (name of the type or the variable) and the value is a list of statements.

The value is a list of statements because we can do this:

```tsx
type test = string;
var test = 'string';
```

For the same `test` identifier's name, we can have two different statements, and the best way to do it is to store them in a list of declarations. Later on, if we want to access one of the declarations, we need to pass the type of statement we're looking for, if it's a type or a variable.

For the above example, we would have the statements stored like this in the `Map`:

```tsx
Map(1) {
  'test' => [
    // The Variable AST node
    {
      kind: Node.Var,
      name: {
        kind: 'Identifier',
        text: 'test',
      },
      init: {
        kind: 'StringLiteral',
        value: 'string',
      },
    },
    // The Type Alias AST node
    {
      kind: Node.TypeAlias,
      name: {
        kind: 'Identifier',
        text: 'test',
      },
      init: {
        kind: 'Identifier',
        text: 'string',
      },
    }
  ]
}
```

So now, the compiler can use this data structure and query the statements. To resolve it, we pass the name and the type of the statement we are looking for.

```tsx
const symbol = locals.get(name);

if (symbol?.declarations.some((d) => d.kind === type)) {
  return symbol;
}
```

What's happening here?

- It gets the symbol based on the `name`
- and then it tries to find the declaration statement based on the `type`

For every AST node created from the parser, the binder will handle them and figure out if it should add or not to the `Map`. And then the type checker can resolve the statement whenever it needs to check the types.

## Values in the type checker

In general, the type checker will do two things: one is to generate a type structure for each node and the second is to compare these types.

For expressions like strings and numbers, it should return the `stringType` and `numberType`. The shape of these types is simple:

```tsx
const stringType: Type = { id: 'string' };
const numberType: Type = { id: 'number' };
```

For statements like variable declaration and assignment, it will compare the returned type from the value and the identifier's type. If you have this variable declaration example:

```tsx
var num: number = '123';
     ⎸
     ↳ Type 'string' is not assignable to type 'number'.
```

It should provide a type error like it was illustrated above, right? The type checker should only compare these two nodes: the identifier `num` with the type `NumericLiteral` and the expression `'123'` with the type `StringLiteral`. We clearly see a mismatch between these two types and the compiler attaches this new error to the “store of errors”.

For assignments, it works pretty much the same way:

```tsx
var num: number = 123;

num = '123';
 ⎸
 ↳ Type 'string' is not assignable to type 'number'.
```

But now it needs to go to the binder and ask for the identifier `num`. It will try to resolve it, get the symbol, and generate the related type. Then it just compares the generated type with the value type.

We are going to see more of this in-depth later on.

---

Now that we understand how each part of the compiler represents characters, tokens, and AST nodes, let's get some features and unpack how they were implemented.

We go from the lexer, passing to the parser and binder, and ending in the type checker.

## `NumericLiteral`: handling numbers

## Resources

- [TypeScript codebase](https://github.com/microsoft/typescript?utm_source=iamtk.co&utm_medium=referral&utm_campaign=tk_newsletter)
- [How the TypeScript Compiler Compiles](https://www.youtube.com/watch?v=X8k_4tZ16qU&utm_source=iamtk.co&utm_medium=referral&utm_campaign=tk_newsletter)
- [mini-typescript](https://github.com/imteekay/mini-typescript)
- [TypeScript Compiler Manual](https://sandersn.github.io/manual/Typescript-compiler-implementation.html?utm_source=iamtk.co&utm_medium=referral&utm_campaign=tk_newsletter)

---

</SmoothRender>
