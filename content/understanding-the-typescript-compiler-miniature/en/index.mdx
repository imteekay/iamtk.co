<SmoothRender>

As you may know, I've been studying compilers. A lot. For the past month, I've been learning more about the TypeScript compiler, reading its source code, and implementing some of the exercises from the [mini-typescript](https://github.com/imteekay/mini-typescript).

In this post, I want to cover some of my learnings while reading the TypeScript compiler miniature's source code and implementing the exercises.

I divided this series into three parts and the following posts to cover everything about the TypeScript compiler. The first two are already published and you can take a look at them here:

- [A High Level Architecture of the TypeScript compiler](https://www.iamtk.co/a-high-level-architecture-of-the-typescript-compiler)
- [JavaScript scope, Closures, and the TypeScript compiler](https://iamtk.co/javascript-scope-closures-and-the-typescript-compiler)

And now, in this post, I will cover different features of the [mini-typescript](https://github.com/imteekay/mini-typescript) and how they are implemented. For the exercises I implemented in the project, I will write new articles in the following posts of the series.

By the way, I think it's a good idea to read the first two posts before reading this if you don't know how compilers work and how the TypeScript compiler works. The first one will give a good overview of the steps of the compiler and how each piece fits together. The second one will talk about closures and how they are used to make the compiler more modular and easier to change.

With the two pieces, I think you'll be ready to read how some of the features of the TypeScript miniature are implemented.

Let's go!

---

Before going into each feature, I just want to illustrate how the compiler structures each step. Basically, how it represents tokens in the lexer step, AST nodes in the parser, variable and type declarations in the binder, and types in the type checker.

## Representing tokens

The idea of a lexer is to go through character by character and produce a new token. It receives the source code as a string and starts from position `0`. In this simplest version, it has states like `pos` as the position of the current character it's analyzing, `token` as the token type of the produced token, and `text` that could be the name of an identifier (e.g. `age` from `var age = 1;`), a number value (e.g. `1`), a keyword (e.g. `var`), or a string value (e.g. `"string"`).

As an example, if we have this source code

```jsx
var age = 1;
```

The lexer will produce this list of tokens

- `var`:
  - `text`: “var”
  - `token`: “Var”
- `age`:
  - `text`: “age”
  - `token`: “Identifier”
- `=`:
  - `text`: undefined
  - `token`: “Equals”
- `1`:
  - `text`: “1”
  - `token`: “NumericLiteral”

In a visible way, it should look like this

[Add illustration: from source code to tokens using this example above]

## Representing AST nodes

AST nodes are basically `Statement`s. They can be `ExpressionStatement`, `Var`, `TypeAlias`, or `EmptyStatement`.

The type looks like a union of all these types

```tsx
type Statement = ExpressionStatement | Var | TypeAlias | EmptyStatement;
```

To have an idea of how AST nodes can be structured, let's take `ExpressionsStatement` as an example and see its data types and the transformation from source code to AST node.

The `ExpressionStatement` can be different expressions: `Identifier`, `NumericLiteral`, `Assignment`, or `StringLiteral`.

```tsx
type Expression = Identifier | NumericLiteral | Assignment | StringLiteral;
```

Each node can have different “attributes”. For example,

- `NumericLiteral` and `StringLiteral` can have a `value` attribute. For `NumericLiteral`, it's a number and for `StringLiteral`, it's a string.
- The `Identifier` has a `text` attribute, that's its name.
- The `Assignment` has the `name` and the `value`.

Let's see how we can represent each of these nodes — their data types

```tsx
interface Identifier {
  kind: Node.Identifier;
  text: string;
  pos: number;
}

interface Assignment {
  kind: Node.Assignment;
  name: Expression;
  value: Expression;
  pos: number;
}

interface NumericLiteral {
  kind: Node.NumericLiteral;
  value: number;
  pos: number;
}

interface StringLiteral {
  kind: Node.StringLiteral;
  value: string;
  pos: number;
}
```

This is already a good node representation for each.

Let's now see examples of each node:

An identifier with name `name`:

```tsx
// source code:
// name;

const identifier = {
  kind: 'Identifier',
  text: 'name',
  pos: 0,
};
```

An assignment with name `age` and value `1`:

```tsx
// source code:
// age = 1;

const assignment = {
  kind: 'Assignment',
  name: {
    // an identifier is an expression
    kind: 'Identifier',
    text: 'age',
    pos: 0,
  },
  value: {
    // a numeric literal is an expression
    kind: 'NumericLiteral',
    value: 1,
    pos: 1,
  },
  pos: 0,
};
```

A numeric literal:

```tsx
// source code:
// 1;

const numericLiteral = {
  kind: 'NumericLiteral',
  value: 1,
  pos: 0,
};
```

A string literal:

```tsx
// source code:
// 'hello';

const stringLiteral = {
  kind: 'StringLiteral',
  value: 'hello',
  pos: 0,
};
```

This already gives us a nice overview of how we can represent the source code in AST nodes. In the following sections, we will dive deeper into each feature and see how this is used in the following steps like the binder and the type checker.

## Binder: storing the type and variable declarations

Here in the binder, one of its responsibilities is storing declarations of types and variables. The compiler stores in a data structure and the statements or AST nodes can be “fetched” later on.

The data structure the compiler uses to store these declarations is a `Map`, a key-value data structure, where the key is the name of the identifier (name of the type or the variable) and the value is a list of statements.

The value is a list of statements because we can do this:

```tsx
type test = string;
var test = 'string';
```

For the same `test` identifier's name, we can have two different statements, and the best way to do it is to store them in a list of declarations. Later on, if we want to access one of the declarations, we need to pass the type of statement we're looking for, if it's a type or a variable.

For the above example, we would have the statements stored like this in the `Map`:

```tsx
Map(1) {
  'test' => [
    // The Variable AST node
    {
      kind: Node.Var,
      name: {
        kind: 'Identifier',
        text: 'test',
      },
      init: {
        kind: 'StringLiteral',
        value: 'string',
      },
    },
    // The Type Alias AST node
    {
      kind: Node.TypeAlias,
      name: {
        kind: 'Identifier',
        text: 'test',
      },
      init: {
        kind: 'Identifier',
        text: 'string',
      },
    }
  ]
}
```

So now, the compiler can use this data structure and query the statements. To resolve it, we pass the name and the type of the statement we are looking for.

```tsx
const symbol = locals.get(name);

if (symbol?.declarations.some((d) => d.kind === type)) {
  return symbol;
}
```

What's happening here?

- It gets the symbol based on the `name`
- and then it tries to find the declaration statement based on the `type`

For every AST node created from the parser, the binder will handle them and figure out if it should add or not to the `Map`. And then the type checker can resolve the statement whenever it needs to check the types.

## Values in the type checker

In general, the type checker will do two things: one is to generate a type structure for each node and the second is to compare these types.

For expressions like strings and numbers, it should return the `stringType` and `numberType`. The shape of these types is simple:

```tsx
const stringType: Type = { id: 'string' };
const numberType: Type = { id: 'number' };
```

For statements like variable declaration and assignment, it will compare the returned type from the value and the identifier's type. If you have this variable declaration example:

```tsx
var num: number = '123';
     ⎸
     ↳ Type 'string' is not assignable to type 'number'.
```

It should provide a type error like it was illustrated above, right? The type checker should only compare these two nodes: the identifier `num` with the type `NumericLiteral` and the expression `'123'` with the type `StringLiteral`. We clearly see a mismatch between these two types and the compiler attaches this new error to the “store of errors”.

For assignments, it works pretty much the same way:

```tsx
var num: number = 123;

num = '123';
 ⎸
 ↳ Type 'string' is not assignable to type 'number'.
```

But now it needs to go to the binder and ask for the identifier `num`. It will try to resolve it, get the symbol, and generate the related type. Then it just compares the generated type with the value type.

We are going to see more of this in-depth later on.

---

Now that we understand how each part of the compiler represents characters, tokens, and AST nodes, let's get some features and unpack how they were implemented.

We go from the lexer, passing to the parser and binder, and ending in the type checker.

## `NumericLiteral`: handling numbers

We first start with the lexer. There it will scan characters and transform them into a token. For `NumericLiteral`s, it needs to read numbers from the source code. This is what we'll be looking for.

The first part is to check if the current character is a possible number.

```tsx
if (/[0-9]/.test(s.charAt(pos))) {
  // ...
}
```

Using regular expressions, we can accomplish this. Check if the character in the position `pos` passes the regex test for any number from 0 to 9. If this character is the one, we know it's a `NumericLiteral`.

Numbers can be just one digit or more. To make sure it gets the entire number, we should keep scanning until we “finish” the number. Now I want to present to you the function `scanForward`. It keeps scanning the source code and moving forward if the predicate is true.

```tsx
function scanForward(pred: (x: string) => boolean) {
  while (pos < s.length && pred(s.charAt(pos))) pos++;
}
```

We also make sure we stop the loop if it reaches the end of the source code. The `pred` is just a predicate function, it will receive the current character and return a boolean, if the character passes the check or not.

In this case, the predicate is if the current character is a number.

```tsx
function isNumber(c: string) {
  return /[0-9]/.test(c);
}
```

So if we run this code:

```tsx
scanForward(isNumber);
```

It will keep scanning forward until it reaches the end of the number or the end of the source code. That's it. Before any operation starts in the lexer, we store the `start` position. When it finished scanning the entire number, the position `pos` went to the last index of the number. To get the `text`, we should just slice that:

```tsx
text = s.slice(start, pos);
```

And to finish it, the token should be a `NumericLiteral`

```tsx
token = Token.NumericLiteral;
```

Now that the compiler finished the “tokenization”, we are now in the parsing process.

Remember that the parser has an instance of the lexer? The instance has functions like `scan`, `token`, `text`, and `pos`.

Before start understanding the parser, let's recall the structure we want to generate for the `NumericLiteral`. You should remember that a number is an expression, so the structure will look like this:

```tsx
{
  kind: Node.ExpressionStatement;
  pos: number;
  expr: {
    kind: Node.NumericLiteral;
    value: number;
    pos: number;
  }
}
```

We should have a statement, more specifically, an expression statement, and the expression is a number. The number will have `NumericLiteral` as its `kind`, the value (e.g. the number `1` will be the `value` if the source code is `1;`), and the position `pos` of the statement.

The parser tries to parse all kinds of statements before an expression, if it doesn't parse anything, it tries parsing the expression. This is the returned value when parsing the statements:

```tsx
{ kind: Node.ExpressionStatement, expr: parseExpression(), pos };
```

When parsing the expression, we want to see if it can parse a number, so it uses a function called `tryParseToken`. That's a very interesting function:

```tsx
function tryParseToken(expected: Token) {
  const ok = lexer.token() === expected;
  if (ok) {
    lexer.scan();
  }
  return ok;
}
```

If it's the expected token, in this case, the `Token.NumericLiteral`, it will scan and return if it's the expected one. That's interesting because it can be used like this:

```tsx
if (tryParseToken(Token.NumericLiteral)) {
  return { kind: Node.NumericLiteral, value: +lexer.text(), pos };
}
```

That's exactly what we need to create the number AST node.

- It tries to parse the token `Token.NumericLiteral` and the current token is the expected one
- It just returns the `NumericLiteral` AST node: take a look that it “cast” the text into a number with the `+` sign (take a look at [unary plus +](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Unary_plus))

And now we have the full AST node for the expression statement.

The binder doesn't do anything regarding the number as we learned that one of its responsibilities is to store the variable and type declarations.

The type checker just produces a number type as we've seen early on. This part is super straightforward. It checks every statement, so when it gets to the expressions and the current expression is a `Node.NumericLiteral`, it just returns a `numberType`, which is this structure

```tsx
const numberType: Type = { id: 'number' };
```

As we've seen before. This is an important type as it will be used for the comparison of types in other checks.

Let's see another statement that's even more interesting. We'll be talking about the variable declaration. Let's understand how the compiler parses and type checks this source code:

```tsx
var num: number = 1;
```

In the tokenization process, let's start with the simplest tokens: Equals (`=`), Semicolon (`;`), and Colon (`:`).

This part is straightforward. If the current character is one of these mentioned earlier, we just assign the right token for that. The code will look pretty much like this:

```tsx
case '=':
  token = Token.Equals;
  break;
case ';':
  token = Token.Semicolon;
  break;
case ':':
  token = Token.Colon;
  break;
```

These tokens will be helpful to parse the entire variable declaration. For example, at least in the first version, the declaration will always expect the `Equals` token after the identifier or the typename.

Now we need to create tokens for the `var`, the name identifier (the name of the variable), and the typename identifier (the name of the type).

All of them are “alphabetical characters” and this is the first hint. Whenever the current character is an alphabetical char, we know we can be scanning a keyword or an identifier. Both will be implemented in the same way.

This looks pretty similar to the `NumericLiteral` we've seen before:

```tsx
if (/[_a-zA-Z]/.test(s.charAt(pos))) {
  // ...
}
```

But now we are looking at alphabetical characters rather than numbers. We even do scanning the same way using the `scanForward` we used before. Identifier can have numbers in its name, so the predicate will be if the character is an alphanumeric char. Here it's:

```tsx
function isAlphanumerical(c: string) {
  return /[_a-zA-Z0-9]/.test(c);
}
```

Let's scan forward all the way to the end of the keyword or the identifier:

```tsx
scanForward(isAlphanumerical);
```

The `text` will be a simple slice between the start position to the end position:

```tsx
text = s.slice(start, pos);
```

And the token is when we separate what's a keyword and what's an identifier. The whole idea is: if the `text` belongs to the “keywords” list, it's a keyword, if not, it's an identifier. This is the “list”, or better, the object:

```tsx
const keywords = {
  function: Token.Function,
  var: Token.Var,
  type: Token.Type,
  return: Token.Return,
};
```

To handle this logic, we use a simple ternary together with the `[in` operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/in):

```tsx
token =
  text in keywords ? keywords[text as keyof typeof keywords] : Token.Identifier;
```

And that's it, the lexer part for the whole variable declaration is done.

[add illustration for the source code to tokens transformation - `var num: number = 1;` - var is keyword, num is identifier, : is Colon, number is identifier, = is Equal, 1 is Numeric Literal, ; is Semicolon]

## Resources

- [TypeScript codebase](https://github.com/microsoft/typescript?utm_source=iamtk.co&utm_medium=referral&utm_campaign=tk_newsletter)
- [How the TypeScript Compiler Compiles](https://www.youtube.com/watch?v=X8k_4tZ16qU&utm_source=iamtk.co&utm_medium=referral&utm_campaign=tk_newsletter)
- [mini-typescript](https://github.com/imteekay/mini-typescript)
- [TypeScript Compiler Manual](https://sandersn.github.io/manual/Typescript-compiler-implementation.html?utm_source=iamtk.co&utm_medium=referral&utm_campaign=tk_newsletter)

---

</SmoothRender>
